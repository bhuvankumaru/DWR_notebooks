{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3857f71-ca55-482f-b6d8-d4ad1d695d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import subprocess\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from mintpy import view, plot_network\n",
    "from mintpy.objects import gnss, timeseries, ifgramStack\n",
    "from mintpy.smallbaselineApp import TimeSeriesAnalysis\n",
    "from mintpy.utils import ptime, readfile, writefile, utils as ut\n",
    "from scipy import signal\n",
    "from skimage.transform import rescale\n",
    "from urllib.request import urlretrieve\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa33ac5-1832-40d6-9c25-e2ed38e0f289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corners(atr):\n",
    "    \"\"\"Get corners coordinate.\"\"\"\n",
    "    length = int(atr['LENGTH'])\n",
    "    width = int(atr['WIDTH'])\n",
    "    W = float(atr['X_FIRST'])\n",
    "    N = float(atr['Y_FIRST'])\n",
    "    lon_step = float(atr['X_STEP'])\n",
    "    lat_step = float(atr['Y_STEP'])\n",
    "    S = N + lat_step * length\n",
    "    E = W + lon_step * width\n",
    "\n",
    "    return S, N, W, E, width, length\n",
    "def rescale_data(data, mask, meta, ref_meta):\n",
    "    \"\"\"rescale matrix into a different resolution\"\"\"\n",
    "\n",
    "    # calc scaling factor\n",
    "    scale = (float(meta['Y_STEP']) / float(ref_meta['Y_STEP']),\n",
    "             float(meta['X_STEP']) / float(ref_meta['X_STEP']))\n",
    "    \n",
    "    data = np.nan_to_num(data,nan=0.0);\n",
    "    # scale\n",
    "    if data.ndim > 2:\n",
    "        data_out = np.stack([rescale(data[i], scale, mode='symmetric', preserve_range=True, order=0) for i in range(data.shape[0])]);\n",
    "        len, wid = data_out.shape[1], data_out.shape[2]\n",
    "    else:\n",
    "        data_out = rescale(data, scale,mode='symmetric', preserve_range=True, order=0);\n",
    "        len, wid = data_out.shape[0], data_out.shape[1]\n",
    "    mask_out = rescale(mask, scale,mode='symmetric', preserve_range=True, order=0);\n",
    "    data_out = np.where(mask_out, data_out, np.nan)\n",
    "    # update metadata\n",
    "    meta['Y_STEP'] = ref_meta['Y_STEP']\n",
    "    meta['X_STEP'] = ref_meta['X_STEP']\n",
    "    meta['LENGTH'], meta['WIDTH'] = len, wid\n",
    "\n",
    "    return data_out, mask_out, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8128d80b-db9a-44e9-925a-1bc06dafb6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# better start with an ARIA product on the north most (west most) part\n",
    "ts_file_list= [r'C:\\Users\\bvarugu\\Documents\\Stockton\\Asc\\mintpy\\corrected_ts_TRE_GNSS.h5',\n",
    "                r'C:\\Users\\bvarugu\\Documents\\Concord\\Asc\\corrected_ts_TRE_GNSS.h5',\n",
    "               r'C:\\Users\\bvarugu\\Documents\\Lamont_Earthquake\\ARIA_products\\Asc\\corrected_ts_TRE_GNSS.h5',\n",
    "               r'C:\\Users\\bvarugu\\Documents\\Losangeles1\\Asc\\mintpy\\corrected_ts_TRE_GNSS.h5',\n",
    "               r'C:\\Users\\bvarugu\\Documents\\Losangeles2\\Asc\\mintpy\\corrected_ts_TRE_GNSS.h5',\n",
    "               r'C:\\Users\\bvarugu\\Documents\\Southbay\\geo\\corrected_ts_TRE_GNSS.h5']\n",
    "mask_file_list= [r'C:\\Users\\bvarugu\\Documents\\Stockton\\Asc\\mintpy\\maskTempCoh_0.9.h5',\n",
    "                r'C:\\Users\\bvarugu\\Documents\\Concord\\Asc\\maskTempCoh_0.9.h5',\n",
    "               r'C:\\Users\\bvarugu\\Documents\\Lamont_Earthquake\\ARIA_products\\Asc\\maskTempCoh_0.9.h5',\n",
    "               r'C:\\Users\\bvarugu\\Documents\\Losangeles1\\Asc\\mintpy\\maskTempCoh_0.9.h5',\n",
    "               r'C:\\Users\\bvarugu\\Documents\\Losangeles2\\Asc\\mintpy\\maskTempCoh_0.9.h5',\n",
    "               r'C:\\Users\\bvarugu\\Documents\\Southbay\\geo\\maskTempCoh_0.9.h5']\n",
    "geom_file_list= [r'C:\\Users\\bvarugu\\Documents\\Stockton\\Asc\\mintpy\\geometryGeo.h5',\n",
    "                r'C:\\Users\\bvarugu\\Documents\\Concord\\Asc\\geometryGeo.h5',\n",
    "               r'C:\\Users\\bvarugu\\Documents\\Lamont_Earthquake\\ARIA_products\\Asc\\geometryGeo.h5',\n",
    "               r'C:\\Users\\bvarugu\\Documents\\Losangeles1\\Asc\\mintpy\\geometryGeo.h5',\n",
    "               r'C:\\Users\\bvarugu\\Documents\\Losangeles2\\Asc\\mintpy\\geometryGeo.h5',\n",
    "               r'C:\\Users\\bvarugu\\Documents\\Southbay\\geo\\geo_geometryRadar.h5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d8399f-e683-498a-89b3-f1edc14b0f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_dates(track1_date_list,track2_date_list):\n",
    "    track1_datestamps = [dt.datetime.strptime(date, \"%Y%m%d\") for date in track1_date_list];\n",
    "    track2_datestamps = [dt.datetime.strptime(date, \"%Y%m%d\") for date in track2_date_list];\n",
    "    common_dates= np.full(len(track1_date_list), np.nan).tolist()\n",
    "    for i, date in enumerate(track1_datestamps):\n",
    "        closest_date = min(track2_datestamps, key=lambda b:abs(date-b));\n",
    "        diff = date-closest_date;#diff = diff.astype(int)\n",
    "        if abs(diff) < dt.timedelta(10):\n",
    "            common_dates[i]= closest_date.strftime(\"%Y%m%d\");\n",
    "    return common_dates\n",
    "disp_data_list = []; mask_list = []; atr_list= [];\n",
    "desired_track_number = 0; #first track in the list\n",
    "for i in range(len(ts_file_list)):\n",
    "    ts_file = ts_file_list[i];\n",
    "    mask = readfile.read(mask_file_list[i])[0]; mask_list.append(mask);   \n",
    "    los_inc_angle = readfile.read(geom_file_list[i], datasetName='incidenceAngle')[0];\n",
    "    if i==desired_track_number:\n",
    "        track1_date_list = timeseries(ts_file).get_date_list();print(track1_date_list)\n",
    "        ref_data, ref_atr = readfile.read(ts_file);\n",
    "        ref_date = track1_date_list[0]; # first date of the track\n",
    "        insar_up = (ref_data)/(np.cos(np.deg2rad(los_inc_angle)));\n",
    "        disp_data_list.append(insar_up);atr_list.append(ref_atr);\n",
    "    else:\n",
    "        dates = timeseries(ts_file).get_date_list();\n",
    "        common_dates = get_common_dates(track1_date_list,dates);\n",
    "        #print(common_dates)\n",
    "        atr = timeseries(ts_file).get_metadata();\n",
    "        if atr['REF_DATE'] != common_dates[0]:\n",
    "            print('Reference date not set to first date. Setting it ....');\n",
    "            iargs = [ts_file, '--ref-date', str(common_dates[0])]\n",
    "            import mintpy.cli.reference_date\n",
    "            mintpy.cli.reference_date.main(iargs)\n",
    "        data = np.zeros([len(ref_data), int(atr['LENGTH']), int(atr['WIDTH'])], dtype=np.float32) * np.nan;\n",
    "        for j, common_date in enumerate(common_dates):\n",
    "            if isinstance(common_date, str) and common_date:  # Ensure it's a valid string\n",
    "                disp = readfile.read(ts_file, datasetName=common_date)[0];\n",
    "                data[j, :, :] = (disp)/(np.cos(np.deg2rad(los_inc_angle)));\n",
    "        disp_data_list.append(data);atr_list.append(atr);\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8e658-526d-4e35-b616-4cb7c064e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid boundaries\n",
    "S,N,W,E = 33,39,-123,-115.5\n",
    "print(\"S N W E :\",S,N,W,E);\n",
    "try:\n",
    "    if ref_atr['X_STEP'] != str(0.000833333):\n",
    "        raise ValueError(\"Set ref atr to an ARIA track\")\n",
    "    else:\n",
    "        print(\"Ref step is:\", ref_atr['X_STEP'])\n",
    "except ValueError as e:\n",
    "    print(\"Error:\", e)\n",
    "# ref_atr['X_STEP'] = 0.000833333; #this is equivalent ot 100m\n",
    "# ref_atr['Y_STEP'] = -0.000833333;\n",
    "lon_step = float(ref_atr['X_STEP'])\n",
    "lat_step = float(ref_atr['Y_STEP'])\n",
    "width  = int(np.ceil((E - W) / lon_step))\n",
    "length = int(np.ceil((S - N) / lat_step))\n",
    "print('Combined matrix shape is:',length,width)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd31ee81-a1e2-4127-95bc-2fb2ddd924d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_bounds=[];N_bounds=[];W_bounds=[];E_bounds=[];lengths=[];widths=[];\n",
    "#S_bounds.append(S1);N_bounds.append(N1);W_bounds.append(W1);E_bounds.append(E1);lengths.append(length1);widths.append(width1)\n",
    "for i,atr in enumerate(atr_list):\n",
    "    ratio_x = abs((float(ref_atr['X_STEP']) - float(atr['X_STEP'])) / float(ref_atr['X_STEP']))\n",
    "    ratio_y = abs((float(ref_atr['Y_STEP']) - float(atr['Y_STEP'])) / float(ref_atr['Y_STEP']))\n",
    "    # print(atr['FILE_PATH'],ratio_x,ratio_y)\n",
    "    if any(ratio > 1e-3 for ratio in [ratio_x, ratio_y]):\n",
    "        print('rescaling the matrix {} into the same spatial resolution as the reference grid'.format(i))\n",
    "        disp_data_list[i], mask_list[i], atr = rescale_data(disp_data_list[i], mask_list[i], meta=atr, ref_meta=ref_atr);\n",
    "        atr_list[i] = atr\n",
    "\n",
    "    # input spatial extents\n",
    "    print('grabbing corners of input matrices')\n",
    "    S_bound, N_bound, W_bound, E_bound, width_bound, length_bound = get_corners(atr);\n",
    "    S_bounds.append(S_bound);N_bounds.append(N_bound);W_bounds.append(W_bound);E_bounds.append(E_bound);lengths.append(length_bound);widths.append(width_bound);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429aee7e-7eba-4411-8185-7186fb56ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('estimate difference in the overlapping area')\n",
    "lon_seq = np.linspace(W, W + width  * lon_step, width, endpoint=False);\n",
    "lat_seq = np.linspace(N, N + length * lat_step, length, endpoint=False);\n",
    "lons,lats= np.meshgrid(lon_seq,lat_seq);\n",
    "num_dates = len(track1_date_list);\n",
    "num_tracks= len(atr_list)\n",
    "merged_ts = np.zeros([num_dates,length, width]) * np.nan;\n",
    "for d in range(num_dates):\n",
    "    mat11 = np.zeros([num_tracks,length, width]) * np.nan;\n",
    "    for i in range(num_tracks):\n",
    "        x1, y1 = np.argmin(np.square(lon_seq - W_bounds[i])), np.argmin(np.square(lat_seq - N_bounds[i]));\n",
    "        disp_data = disp_data_list[i][d]; mask = mask_list[i];\n",
    "        disp_data[mask==0] = np.nan;\n",
    "        mat11[i, y1:y1+lengths[i], x1:x1+widths[i]] = disp_data;\n",
    "    merged_ts[d,:,:] = np.nanmean(mat11,axis=0);\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39579aaf-1c5e-4a02-bcfe-5e9b1cd85a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "atr = dict()\n",
    "for key, value in ref_atr.items():\n",
    "    atr[key] = value\n",
    "atr['FILE_TYPE'] = 'timeseries'\n",
    "atr['WIDTH']  = str(width)\n",
    "atr['LENGTH'] = str(length)\n",
    "atr['X_STEP'] = str(lon_step)\n",
    "atr['Y_STEP'] = str(lat_step)\n",
    "atr['X_FIRST'] = str(W)\n",
    "atr['Y_FIRST'] = str(N)\n",
    "print(f'update LENGTH/WIDTH: {length}/{width}')\n",
    "print(f'update Y/X_FIRST: {N}/{W}')\n",
    "\n",
    "# update REF_Y/X\n",
    "coord = ut.coordinate(atr)\n",
    "ref_y, ref_x = coord.geo2radar(float(atr['REF_LAT']), float(atr['REF_LON']))[:2]\n",
    "atr['REF_Y'], atr['REF_X'] = ref_y, ref_x\n",
    "print(f'update REF_Y/X: {ref_y}/{ref_x}')\n",
    "\n",
    "# delete SUBSET_Y/XMIN/MAX\n",
    "for key in ['SUBSET_XMIN', 'SUBSET_XMAX', 'SUBSET_YMIN', 'SUBSET_YMAX']:\n",
    "    if key in atr.keys():\n",
    "        atr.pop(key)\n",
    "        print(f'remove {key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8e958f-ff61-4dbf-9951-d02c48734452",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_outname = r'C:\\Users\\bvarugu\\Documents\\merged_asc_GNSS_corrected_timeseries_TRE_GNSS.h5'\n",
    "final_dates = np.array(track1_date_list, dtype=np.bytes_);\n",
    "ts_dict = {\n",
    "    \"date\"       : final_dates,\n",
    "    \"timeseries\" : merged_ts,\n",
    "}\n",
    "writefile.write(ts_dict,file_outname,metadata=atr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbb35a4-0d44-46e3-b84f-018f4f629ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# southbay_atr = atr_list[-1].copy();\n",
    "# south_bay_data = disp_data_list[-1].copy();\n",
    "# southbay_mask = mask_list[-1].copy();\n",
    "# southbay_data_out, mask_out, atr_out = rescale_data(south_bay_data, southbay_mask, meta=southbay_atr, ref_meta=ref_atr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea8f55c-02dd-4d9f-9f7d-aa60b294f63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(disp_data_list[0][45],cmap='jet',vmin=-0.1,vmax=0.1,interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e796c31f-8567-4383-a86e-5e13dc3adf69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mintpy",
   "language": "python",
   "name": "mintpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
