{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc27a083-41dd-4a8c-b968-a4fb117916f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from mintpy.objects import sensor\n",
    "from mintpy.utils import ptime, readfile, utils as ut, writefile\n",
    "from mintpy.objects.stack import timeseries\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce97158e-2b1c-4313-aa3f-ddc7f564015f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lat', 'Lon', 'D20220401', 'D20220501', 'D20220601', 'D20220701', 'D20220801', 'D20220901', 'D20221001', 'D20221101', 'D20221201', 'D20230101', 'D20230201', 'D20230301', 'D20230401', 'D20230501', 'D20230601', 'D20230701', 'D20230801', 'D20230901', 'D20231001', 'D20231101', 'D20231201', 'D20240101', 'D20240201', 'D20240301', 'D20240401', 'D20240501', 'D20240601', 'D20240701', 'D20240801', 'D20240901']\n"
     ]
    }
   ],
   "source": [
    "timseries_file =  r'C:\\Users\\bvarugu\\Documents\\merged_UP_GNSS_corrected_timeseries_TRE_GNSS.h5';\n",
    "output_dir =  r'C:\\Users\\bvarugu\\Documents\\timseries2csv';\n",
    "output_unit = 'mm';\n",
    "output_prefix = \"ARIA_VERT_TS\"\n",
    "os.makedirs(output_dir,exist_ok = True);\n",
    "chunk_size=1000000;\n",
    "obj = timeseries(timseries_file);\n",
    "ts_atr = obj.get_metadata();\n",
    "ts_dates = obj.get_date_list();\n",
    "col_names = [\"Lat\", \"Lon\"] + [f\"D{date}\" for date in ts_dates]\n",
    "print(col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8a1b59f-df76-407c-b1de-09e0ffbb48ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = ut.coordinate(ts_atr)\n",
    "ys, xs = np.indices([int(ts_atr['LENGTH']),int(ts_atr['WIDTH'])]);\n",
    "lats, lons = coord.radar2geo(ys.flatten(),xs.flatten())[:2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84149c28-083b-42df-ad64-7d2a103c6c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_unit == 'ft':\n",
    "    conv_factor = 3.28084;\n",
    "elif output_unit == 'mm':\n",
    "    conv_factor = 1000;\n",
    "else:\n",
    "    conv_factor = 1.0;\n",
    "data_series = [];\n",
    "for i,date in enumerate(ts_dates):\n",
    "    data = readfile.read(timseries_file, datasetName=date)[0];\n",
    "    data *= conv_factor;data = np.round(data,1);\n",
    "    data_series.append(data.flatten())\n",
    "data_series = np.column_stack(data_series)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5327935-484a-45e0-97c0-1ab42a1c498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = np.column_stack([np.array(lats).flatten(), np.array(lons).flatten()]);\n",
    "coords = coords.astype(np.float32);\n",
    "valid_mask = ~np.all(np.isnan(data_series), axis=1)\n",
    "coords = coords[valid_mask]\n",
    "data_series = data_series[valid_mask];data_series = data_series.astype(np.float32);\n",
    "data_series = np.where(np.isnan(data_series), \"<Null>\", data_series);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ff50c3d-50c5-4f57-b24e-2888f96d7042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_points = data_series.shape[0];\n",
    "num_chunks = int(np.ceil(num_points / chunk_size));\n",
    "print(num_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e37abaad-164c-47f2-9c3b-f7c78841b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for chunk_idx in range(num_chunks):\n",
    "#     start = chunk_idx * chunk_size\n",
    "#     end = min((chunk_idx + 1) * chunk_size, num_points)\n",
    "#     chunk_data = data_series[start:end];\n",
    "#     chunk_coords = coords[start:end];\n",
    "#     combined_data = np.column_stack([chunk_coords, chunk_data]);\n",
    "\n",
    "#     # Create a DataFrame for the chunk\n",
    "#     chunk_df = pd.DataFrame(combined_data, columns=col_names)\n",
    "\n",
    "#     # Save the chunk to a CSV file\n",
    "#     output_csv = f\"{output_prefix}_{chunk_idx + 1}.csv\";\n",
    "#     output_csv = os.path.join(output_dir,output_csv)\n",
    "#     chunk_df.to_csv(output_csv, index=False)\n",
    "#     print(f\"Saved chunk {chunk_idx + 1} to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dc298da-2331-4f55-a046-39a11a46e59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_stack = np.column_stack([coords, data_series]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3842ef18-1236-4a86-8b9d-cb0fbf76226f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved chunk to C:\\Users\\bvarugu\\Documents\\timseries2csv\\ARIA_VERT_TS_full_data_ft.csv\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(combined_data_stack, columns=col_names);\n",
    "output_csv = f\"{output_prefix}_full_data_{output_unit}.csv\";\n",
    "output_csv = os.path.join(output_dir,output_csv)\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"Saved chunk to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5796963-cd42-4b25-83fa-905b78821480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mintpy",
   "language": "python",
   "name": "mintpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
